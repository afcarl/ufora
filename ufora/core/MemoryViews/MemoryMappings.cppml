/***************************************************************************
    Copyright 2016 Ufora Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
****************************************************************************/

#include "MemoryMappings.hppml"

MemoryMappings::MemoryMappings(
            AllocationZoneMapping& inZoneMappings,
            PhysicalAllocations& inPhysicalAllocations,
            boost::function<bool (uint8_t* sharedBase, uint64_t sharedOffset, uint8_t* mapBase, uint64_t mapOffset, uint64_t bytecount)> inMapper,
            boost::function<bool (uint8_t* mapBase, uint64_t mapOffset, uint64_t bytecount)> inUnmapper
            ) :
        mMapper(inMapper),
        mUnmapper(inUnmapper),
        mZoneMappings(inZoneMappings),
        mPhysicalAllocations(inPhysicalAllocations)
    {
    }

void MemoryMappings::removeAllMappingsFor(PhysicalMemoryAllocation alloc)
    {
    for (auto objectAndRange: mMappings[alloc])
        {
        LOG_DEBUG << "Unmapping " << objectAndRange.first << " and " << objectAndRange.second;

        mUnmapper(
            mPhysicalAllocations.getMappableAddress(objectAndRange.first),
            objectAndRange.second.low(),
            objectAndRange.second.size()
            );
        mBytesMapped[objectAndRange.first].removeRange(objectAndRange.second);
        }

    mMappings.erase(alloc);
    }

void MemoryMappings::blockedThreadExists(
            BlockOrViewId object,
            RangeToZoneMapping zoneMapping
            )
    {
    lassert(zoneMapping.byteRangeInObject().size() == mZoneMappings.pageSize());

    //see if this block is new or not
    if (mZoneMappableRegions[zoneMapping.zoneContainingData()].rangeContaining(zoneMapping.byteRangeInZone().low()))
        {
        LOG_DEBUG << zoneMapping << " looks immediately mappable.";

        //we can map it
        ensureRangeMapped(object, zoneMapping);
        }
    else
        {
        LOG_DEBUG << zoneMapping << " not mappable: " <<
            mZoneMappableRegions[zoneMapping.zoneContainingData()].getRangeStartsAndEnds();

        mPendingMappings[zoneMapping.zoneContainingData()].push_back(make_pair(object, zoneMapping));
        }
    }

void MemoryMappings::zoneNeeds(AllocationZone zone, IntegerRange byteRangeInZone, const std::vector<pair<MemoryBlockId, IntegerRange> >& inNeededBlockData)
    {
    lassert(inNeededBlockData.size());

    for (auto blockAndRange: inNeededBlockData)
        {
        mZonesAwaitingBlockData[make_pair(zone,byteRangeInZone)][blockAndRange.first].addRange(blockAndRange.second);
        mZonesAwaitingBlockDataBlocks.insert(make_pair(zone,byteRangeInZone), blockAndRange.first);
        }
    }

void MemoryMappings::blockDataProvided(MemoryBlockId block, IntegerRange range)
    {
    std::set<pair<AllocationZone, IntegerRange> > toCheck = mZonesAwaitingBlockDataBlocks.getKeys(block);

    for (auto& zoneAndRange: toCheck)
        {
        mZonesAwaitingBlockData[zoneAndRange][block].removeRange(range);

        if (mZonesAwaitingBlockData[zoneAndRange][block].isEmpty())
            {
            mZonesAwaitingBlockData[zoneAndRange].erase(block);
            mZonesAwaitingBlockDataBlocks.drop(zoneAndRange, block);
            }

        if (mZonesAwaitingBlockData[zoneAndRange].size() == 0)
            {
            mZonesToTryToMap.push_back(zoneAndRange);
            mZonesAwaitingBlockData.erase(zoneAndRange);
            }
        }
    }

void MemoryMappings::deallocatePhysicalMemory(PhysicalMemoryAllocation alloc)
    {
    lassert(mMappings.find(alloc) == mMappings.end());
    lassert(mPendingMappings.find(alloc.zone()) == mPendingMappings.end());

    mZoneMappableRegions[alloc.zone()].removeRange(alloc.byteRange());
    }

void MemoryMappings::zoneIsNowMappable(AllocationZone zone, IntegerRange range)
    {
    mZoneMappableRegions[zone].addRange(range);

    LOG_DEBUG << zone << " added "
        << range << ": " << mZoneMappableRegions[zone].getRangeStartsAndEnds();

    std::vector<pair<BlockOrViewId, RangeToZoneMapping> >& mappings = mPendingMappings[zone];

    for (long k = 0; k < mappings.size(); k++)
        if (mZoneMappableRegions[zone].completelyContainsRange(mappings[k].second.byteRangeInZone()))
            {
            ensureRangeMapped(mappings[k].first, mappings[k].second);
            mappings.erase(mappings.begin() + k);
            k--;
            }

    if (mappings.size() == 0)
        mPendingMappings.erase(zone);
    }

void MemoryMappings::extractZonesToTryToMap(std::vector<pair<AllocationZone, IntegerRange> >& outZones)
    {
    outZones.clear();
    std::swap(outZones, mZonesToTryToMap);

    LOG_DEBUG << "Have " << mPendingMappings.size() << " pending mappings and " << mZonesAwaitingBlockData.size() << " awaiting block data.";
    }

bool MemoryMappings::hasZonesToTryToMap() const
    {
    return mZonesToTryToMap.size();
    }

bool MemoryMappings::byteIsMapped(BlockOrViewId object, int64_t byteOffset)
    {
    return mBytesMapped[object].contains(byteOffset);
    }

void MemoryMappings::ensureRangeMapped(BlockOrViewId object, RangeToZoneMapping mapping)
    {
    IntegerRange zoneInObject = mapping.byteRangeInObject();

    std::vector<IntegerRange> bytesInObjectToMap;

    mBytesMapped[object].rangesNotCovered(zoneInObject, bytesInObjectToMap);

    for (auto range: bytesInObjectToMap)
        {
        mBytesMapped[object].addRange(range);

        LOG_DEBUG << "Mapping " << object << " and " << range;

        mapByteRange(object, mapping.restrictedToObjectRange(range));
        }
    }

void MemoryMappings::mapByteRange(BlockOrViewId object, RangeToZoneMapping mapping)
    {
    std::vector<IntegerRange> physicalRanges;

    mPhysicalAllocations.allocationsForZone(mapping.zoneContainingData())
        .rangesIntersecting(mapping.byteRangeInZone(), physicalRanges);

    for (auto range: physicalRanges)
        {
        auto restricted = mapping.restrictedToZoneRange(range.intersect(mapping.byteRangeInZone()));

        mapByteRange(
            object,
            restricted.byteRangeInObject(),
            PhysicalMemoryAllocation(mapping.zoneContainingData(), range),
            restricted.byteRangeInZone() - range.low()
            );
        }
    }

void MemoryMappings::mapByteRange(BlockOrViewId object, IntegerRange rangeInObject, PhysicalMemoryAllocation alloc, IntegerRange rangeInAlloc)
    {
    lassert(rangeInObject.size() == rangeInAlloc.size());

    LOG_DEBUG << "Mapping " << object << " and " << rangeInObject;

    mMapper(
        mPhysicalAllocations.addressForAllocation(alloc),
        rangeInAlloc.low(),
        mPhysicalAllocations.getMappableAddress(object),
        rangeInObject.low(),
        rangeInObject.size()
        );

    mMappings[alloc].push_back(make_pair(object, rangeInObject));
    }

bool MemoryMappings::zoneHasPendingMappings(AllocationZone zone) const
    {
    if (mPendingMappings.find(zone) != mPendingMappings.end())
        return true;

    for (auto& zoneAndRangePair: mZonesAwaitingBlockData)
        if (zoneAndRangePair.first.first == zone)
            return true;

    return false;
    }
