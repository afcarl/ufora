/***************************************************************************
    Copyright 2015 Ufora Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
****************************************************************************/

#pragma once

#include <string>
#include <boost/thread.hpp>
#include "../Core/ImplValContainer.hppml"
#include "../../core/PolymorphicSharedPtr.hpp"
#include "../Native/NativeCode.hppml"
#include "../Native/NativeType.hppml"
#include "../Core/Type.hppml"

class CUDAExecutionContextInternalState;
class NativeCFG;
class Runtime;
class Type;
class NativeType;

class CUDAExecutionContext :
		public PolymorphicSharedPtrBase<CUDAExecutionContext> {
private:
	//pushes a kernel into the execution context
	//throws an exception if nativeCFGIsValidPTXVectorApplyKernel
	//is false with argument inCFG
	void	define(			const std::string& inKernelName,
							const NativeCFG& inCFG,
							const Type& inInputType,
							const std::vector<Type>& inOutputTypes);

	//execute the kernel defined by inKernelName,
	//and return the new vector.
	//will throw an exception if halted or there
	//is any other problem
	ImplValContainer	executeKernel(
							const std::string&	inKernelName,
							ImplValContainer	inApplyObject,
							ImplValContainer	inSourceVector
							);

public:
	CUDAExecutionContext();

	ImplValContainer	executeKernel(
							ImplValContainer	inApplyObject,
							ImplValContainer	inSourceVector
							);
private:
	// Perhaps replace with tuple
	class InputOutputTypes {
	public:
		InputOutputTypes(
			const Type& inType, const std::vector<Type> outTypes,
			const NativeType& inNativeType, const std::vector<NativeType> outNativeTypes
			) : inputType(inType),
				outputTypes(outTypes),
				inputNativeType(inNativeType),
				outputNativeTypes(outNativeTypes)
			{}

		Type inputType;
		std::vector<Type> outputTypes;
		NativeType inputNativeType;
		std::vector<NativeType> outputNativeTypes;
	};

	// Refactor: merge these maps
	map<std::string, NativeCFG> mNativeKernelsByName;

	map<std::string, std::string> mPTXKernelsByName;

	map<std::string, std::string> mPTXKernelFunctionNames;

	map<std::string, InputOutputTypes > mInputOutputTypesByName;

	map<std::string, bool> mMayThrowException;

	CUDAExecutionContextInternalState* mCUDAState;

	boost::recursive_mutex mMutex;
};
