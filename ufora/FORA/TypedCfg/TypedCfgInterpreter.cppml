/***************************************************************************
    Copyright 2016 Ufora Inc.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
        http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
****************************************************************************/

#include "TypedCfgInterpreter.hppml"
#include "../Reasoner/SimpleForwardReasoner.hppml"
#include "../Core/ExecutionContextScope.hppml"
#include "../Core/ExecutionContext.hppml"
#include "../Core/StackFrame.hpp"
#include "../Core/StackFrameAllocator.hpp"
#include "../Core/RefcountPool.hppml"
#include "../Core/TupleCategory.hppml"
#include "../Runtime.hppml"
#include "../TypedFora/ABI/VectorLoadRequest.hppml"
#include "../TypedFora/TypedFora.hppml"

using namespace Fora::Interpreter;

TypedCfgInterpreter::TypedCfgInterpreter(
				TypedCfgInterpreterStackFrame* inFrame, 
				StackFrameAllocator& allocator, 
				uword_t curCont
				) :
		mCurrentFrame(inFrame),
		mStackAllocator(allocator),
		mCurrentContinuation(curCont),
		mTypedForaCompiler(&*Runtime::getRuntime().getTypedForaCompiler()),
		mRefcountPool(ExecutionContext::currentExecutionContext()->getRefcountPool())
	{

	}

NativeRuntimeContinuationValue<1> TypedCfgInterpreter::interpreter(
                                StackFrame** memory,
                                uword_t continuation,
                                void* typedCfgInterpStackFramePtr
                                )
	{
	ExecutionContext* executionContextPtr = ExecutionContext::currentExecutionContext();
	lassert(executionContextPtr);

	//track the fact that we're in the interpreter
	ExecutionContextScope ecScope(*executionContextPtr, ExecutionContextScope::interpreter);

	TypedCfgInterpreterStackFrame* frame = (TypedCfgInterpreterStackFrame*)typedCfgInterpStackFramePtr;

	TypedCfgInterpreter interpreter(frame, *(*memory)->allocator(), continuation);

	while (!interpreter.done())
		interpreter.step();

	return interpreter.toFollow();
	}

bool TypedCfgInterpreter::done() const
	{
	return (bool)mContinuationToExitAndFollow;
	}

NativeRuntimeContinuationValue<1> TypedCfgInterpreter::toFollow() const
	{
	return *mContinuationToExitAndFollow;
	}

void TypedCfgInterpreter::followUntypedContinuationWithInterpreterResult(const ControlFlowContinuation& cont)
	{
	mIndexOfReturnInParent = null();

	@match ControlFlowContinuation(cont)
		-| Return(arg, isException) ->> {
				
			auto parentFrame = mCurrentFrame->getParentFrame();
			if (parentFrame)
				{
				parentFrame->getResultValue() = constructArgument(arg);
				
				mCurrentContinuation = isException ? 
					continuation_resume_with_exception_result : 
					continuation_resume_with_normal_result
					;

				TypedCfgInterpreterStackFrame::destroy(mCurrentFrame, mStackAllocator);

				mCurrentFrame = parentFrame;
				}
			else
				{
				NativeRuntimeContinuationValue<1> toFollow = 
					mCurrentFrame->getContinuations()[isException ? 1 : 0];

				((ImplVal*)toFollow.slots()[0].target())[0] = constructArgument(arg);

				mContinuationToExitAndFollow = toFollow;
				}
			}
		-| Node(label, args) ->> {
			uint8_t newValStorage[args.size() * sizeof(ImplVal)];
			ImplVal* newVals = (ImplVal*)newValStorage;

			for (long k = 0; k < args.size(); k++)
				newVals[k] = constructArgument(args[k]);

			for (long k = 0; k < args.size(); k++)
				mCurrentFrame->frameValue(k) = newVals[k];

			mCurrentFrame->advanceGraphLabelTo(null() << label);

			mCurrentContinuation = continuation_execute_from_node;
			}
	}

void TypedCfgInterpreter::followContinuation(const TypedCfgStats::Continuation& cont)
	{
	@match TypedCfgStats::Continuation(cont)
		-| Return(arg, isException, indexInParentConts) ->> {
			auto parentFrame = mCurrentFrame->getParentFrame();
			if (parentFrame)
				{
				//we're returning to another typedCFG frame that is the correct caller for this frame
				if (parentFrame->getNodePtr() && parentFrame->getIntendedApplyGraphPtr() == mCurrentFrame->getNodePtr()->graphPtr())
					mIndexOfReturnInParent = indexInParentConts;

				parentFrame->getResultValue() = constructArgument(arg);
				mCurrentContinuation = isException ? 
					continuation_resume_with_exception_result : 
					continuation_resume_with_normal_result
					;

				TypedCfgInterpreterStackFrame::destroy(mCurrentFrame, mStackAllocator);

				mCurrentFrame = parentFrame;
				}
			else
				{
				mIndexOfReturnInParent = null();
				NativeRuntimeContinuationValue<1> toFollow = 
					mCurrentFrame->getContinuations()[isException ? 1 : 0];

				((ImplVal*)toFollow.slots()[0].target())[0] = constructArgument(arg);

				mContinuationToExitAndFollow = toFollow;
				}
			}
		-| Jump(args, nodePtr) ->> {

			lassert_dump(
				!nodePtr->body().isInvalidNode(),
				"Tried to flow to an invalid node"
				);

			uint8_t newValStorage[args.size() * sizeof(ImplVal)];
			ImplVal* newVals = (ImplVal*)newValStorage;

			for (long k = 0; k < args.size(); k++)
				newVals[k] = constructArgument(args[k]);

			for (long k = 0; k < args.size(); k++)
				mCurrentFrame->frameValue(k) = newVals[k];

			mCurrentFrame->advanceNodePtrTo(nodePtr);

			mCurrentContinuation = continuation_execute_from_node;
			}
	}

namespace {

bool tupleMatchesArity(ImplVal value, int arity, bool arityExact)
	{
	auto t = value.type();
	if (t.isTuple())
		{
		int64_t arityOfInterpreterValue = t.getTuple().types().size();
		if (arityOfInterpreterValue == arity || !arityExact && arityOfInterpreterValue >= arity)
			return true;
		}

	return false;
	}

}

ImplVal TypedCfgInterpreter::constructApplyArgumentWithoutNameInfo(const ControlFlowApplyArg& arg)
	{
	@match ControlFlowApplyArg(arg)
		-| Normal(_, a) ->> { return constructArgument(a); }
		-| TupleCall(a) ->> { return constructArgument(a); }
	}

ImplVal TypedCfgInterpreter::constructArgument(const ControlFlowArg& arg)
	{
	@match ControlFlowArg(arg)
		-| Arg(i) ->> {
			return mCurrentFrame->frameValue(i);
			}
		-| Constant(c) ->> {
			return c.getReference();
			}
	}

ImplVal TypedCfgInterpreter::constructArgument(const ControlFlowContinuationArg& arg)
	{
	@match ControlFlowContinuationArg(arg)
		-| Arg(a) ->> {
			return constructArgument(a);
			}
		-| Result() ->> {
			return mCurrentFrame->getResultValue();
			}
		-| TupleElement(k) ->> {
			lassert_dump(
				mCurrentFrame->getNodePtr()->body().isTupleExpand() ||
					mCurrentFrame->getNodePtr()->body().isTupleExpandJump(), 
				prettyPrintString(mCurrentFrame->getNodePtr()->body().tagName())
				);

			int64_t argIndex;
			@match TypedCfgStats::NodeBody(mCurrentFrame->getNodePtr()->body())
				-| TupleExpand(ix) ->> { argIndex = ix; }
				-| TupleExpandJump(ix) ->> {argIndex = ix; }

			ImplVal resVal = mCurrentFrame->frameValue(argIndex);

			lassert(resVal.type().isTuple());

			//because these are pooled values, this is OK
			return mRefcountPool->add(
				ImplVal(
					resVal.type().getTuple().types()[k], 
					(uint8_t*)resVal.data() + resVal.type().byteOffsets()[k]
					)
				);
			}
		-| TupleRemainingElements() ->> {
			lassert_dump(
				mCurrentFrame->getNodePtr()->body().isTupleExpand() ||
					mCurrentFrame->getNodePtr()->body().isTupleExpandJump(), 
				prettyPrintString(mCurrentFrame->getNodePtr()->body().tagName())
				);

			int64_t argIndex;
			int64_t targetArity;
			
			@match TypedCfgStats::NodeBody(mCurrentFrame->getNodePtr()->body())
				-| TupleExpand(ix, (arity, _, _)) ->> { argIndex = ix; targetArity = arity; }
				-| TupleExpandJump(ix, arity) ->> {argIndex = ix; targetArity = arity; }
			
			ImplVal resVal = mCurrentFrame->frameValue(argIndex);

			lassert(resVal.type().isTuple());

			return mRefcountPool->add(
				ImplVal(
					Type::Tuple(
						resVal.type().getTuple().types().slice(targetArity),
						resVal.type().getTuple().names().slice(targetArity)
						),
					(uint8_t*)resVal.data() + resVal.type().byteOffsets()[targetArity]
					)
				);
			}
		-| MakeTuple(args) ->> {
			ImmutableTreeVector<std::pair<ImplValContainer, Nullable<Symbol>>> tupleElts;

			for (auto arg: args)
				{
				@match ControlFlowContinuationTupleArg(arg)
					-| Normal(name, arg) ->> {
						tupleElts = tupleElts + make_pair(ImplValContainer(constructArgument(arg)), name);
						}
					-| TupleCall(arg) ->> {
						ImplValContainer val(constructArgument(arg));
						Nullable<uword_t> size = val.tupleGetSize();
						if (!size)
							tupleElts = tupleElts + make_pair(val, Nullable<Symbol>());
						else
							for (long k = 0; k < *size; k++)
								tupleElts = tupleElts + make_pair(*val.tupleGetItem(k), val.tupleGetName(k));
						}
				}

			ImplValContainer tuple(tupleElts);

			return mRefcountPool->add(tuple.getReference());
			}
	}

void TypedCfgInterpreter::step()
	{
	static int instructionCount = 0;
	instructionCount++;

	if (instructionCount % 100000 == 0)
		LOG_TEST << instructionCount;

	if (mCurrentFrame->getNodePtr() == nullptr)
		{
		if (mCurrentContinuation == continuation_execute_from_node)
			invokeReasonerToGetNewNodePtr();
		else
			{
			@match ControlFlowNodeBody(mCurrentFrame->getGraph()[mCurrentFrame->getLabel()].body())
				-| Apply(_, normal, excep) ->> {
					followUntypedContinuationWithInterpreterResult(
						mCurrentContinuation == continuation_resume_with_normal_result ? normal : excep
						);
					}
				-| Cached(_, normal, excep) ->> {
					followUntypedContinuationWithInterpreterResult(
						mCurrentContinuation == continuation_resume_with_normal_result ? normal : excep
						);
					}

			return;
			}
		}

	if (mCurrentContinuation == continuation_execute_from_node)
		{
		if (mCurrentFrame->getCallbacks()->checkInterruptFlag())
			{
			followInterruptContinuation(null());
			return;
			}

		@match TypedCfgStats::NodeBody(mCurrentFrame->getNodePtr()->body())
			-| Apply(args, Graph(targetNodePtr), normalConts, exceptConts) ->> {
				lassert_dump(
					!targetNodePtr->body().isInvalidNode(),
					"Tried to call an invalid node applying " << 
						prettyPrintString(mCurrentFrame->getNodePtr()->judgments()) << " and "
						<< prettyPrintString(args)
						<< " with conts " << prettyPrintString(normalConts) << " and " << prettyPrintString(exceptConts)
						);

				auto newFrame = TypedCfgInterpreterStackFrame::allocate(
					mStackAllocator, 
					mCurrentFrame,
					targetNodePtr,
					mCurrentFrame->getCallbacks()
					);

				for (long k = 0; k < args.size();k++)
					newFrame->frameValue(k) = constructApplyArgumentWithoutNameInfo(args[k]);

				mCurrentFrame = newFrame;
				}
			-| Apply(args, NativeAxiom(axiom, funcPtr), normalConts, exceptConts) ->> {
				stepNativeAxiom();
				}
			-| Cached(args, normalCont, excepCont) ->> {
				lassert_dump(false, "not implemented");
				}
			-| Branch(argIndex, ifTrue, ifFalse) ->> {
				if (mCurrentFrame->frameValue(argIndex).convertToBoolean())
					followContinuation(ifTrue);
				else
					followContinuation(ifFalse);
				}
			-| TupleExpand(arg, (arity, arityIsExact, ifMatch), ifNoMatch) ->> {
				bool matches = tupleMatchesArity(mCurrentFrame->frameValue(arg), arity, arityIsExact);

				if (matches)
					followContinuation(ifMatch);
				else
					followContinuation(ifNoMatch);
				}
			-| Switch(argIndex, branches, otherwise) ->> {
				ImplVal val = mCurrentFrame->frameValue(argIndex);

				for (auto valueAndCont: branches)
					{
					CSTValue testVal = valueAndCont.first;

					if (testVal.type() == val.type() && val.type().cmp(val.data(), testVal.getData()) == 0)
						{
						followContinuation(valueAndCont.second);
						return;
						}
					}

				followContinuation(otherwise);
				}
			-| Jump(continuation) ->> {
				followContinuation(continuation);
				}
			-| TupleExpandJump(_, _, continuation) ->> {
				followContinuation(continuation);
				}
			-| TransferToInterpreter() ->> {
				invokeReasonerToGetNewNodePtr();
				}
		}
	else
		{
		bool isExceptionResumption = mCurrentContinuation == continuation_resume_with_exception_result;

		@match TypedCfgStats::NodeBody(mCurrentFrame->getNodePtr()->body())
			-| Apply(args, Graph(targetNodePtr), normalConts, exceptConts) ->> {
				const auto& whichSet = isExceptionResumption ? exceptConts : normalConts;

				JudgmentOnResult whichReturns = 
					targetNodePtr->graphPtr()->exits().jorByIsException(isExceptionResumption);

				lassert_dump(whichSet.size() == whichReturns.size(), prettyPrintString(whichSet) << " vs. " << prettyPrintString(whichReturns));

				if (!mIndexOfReturnInParent)
					{
					Nullable<uword_t> whichIndex = whichReturns.smallestCovering(mCurrentFrame->getResultValue());
					if (!whichIndex)
						{
						//this can happen when the child stackframe moves to a different typing graph,
						//usually because we're unwinding up the stack after resuming from a cachecall.
						//we handle this by wiping our typing information and continuing as if we were
						//untyped.
						mCurrentFrame->replaceTypedCfgNodeWithGraphAndLabel();
						return;
						}


					mIndexOfReturnInParent = *whichIndex;

					lassert_dump(
						whichSet.size() > *mIndexOfReturnInParent,
						"can't find " << *mIndexOfReturnInParent << " in " << prettyPrintString(whichSet)
						);
					}

				lassert_dump(
					whichSet.size() > *mIndexOfReturnInParent,
					"can't find " << *mIndexOfReturnInParent << " in " << prettyPrintString(whichSet) 
						<< " with " << prettyPrintString(whichReturns)
					);

				long index = *mIndexOfReturnInParent;
				mIndexOfReturnInParent = null();
				
				followContinuation(whichSet[index]);
				return;
				}
			-| Cached(args, normalCont, excepCont) ->> {
				followContinuation(isExceptionResumption ? excepCont : normalCont);
				return;
				}
			-| _ ->> {}
		
		lassert_dump(false, "this should never happen");
		}	
	}

void TypedCfgInterpreter::invokeReasonerToGetNewNodePtr()
	{
	ImmutableTreeVector<JOV> jovs;
	auto graph = mCurrentFrame->getGraph();
	auto label = mCurrentFrame->getLabel();

	long valueCount = graph[label].argCount();

	for (long k = 0; k < valueCount; k++)
		jovs = jovs + relaxedJOV(JOV::FromLiveValue(mCurrentFrame->frameValue(k)));

	double t0 = curClock();

	mCurrentFrame->advanceNodePtrTo(
		Runtime::getRuntime().getReasoner()->reasonAndProduceNodePtr(
			Fora::ReasonerEntrypoint(
				graph,
				label,
				jovs
				)
			)
		);
	
	if (curClock() - t0 > .5)
		LOG_TEST << "Done re-transferring, which took " << curClock() - t0 << " at " << graph.graphName() << " and label " << label << " with " 
			<< prettyPrintStringWithoutWrapping(jovs)
			<< " at " << graph[label];
	}

void TypedCfgInterpreter::stepNativeAxiom()
	{
	@match TypedCfgStats::NodeBody(mCurrentFrame->getNodePtr()->body())
		-| Apply(args, NativeAxiom(axiom, weakenedAxiom, jumpPtr), normalConts, exceptConts) ->> {
			uint64_t bytecount = sizeof(NativeRuntimeContinuationValue<2>) + sizeof(NativeRuntimeCallbacks*);

			JOVT axiomArgJovt = weakenedAxiom.callSignature();

			for (long k = 0; k < axiomArgJovt.jovs().size(); k++)
				if (axiomArgJovt.jovs()[k].constant())
					{
					}
					else
				if (axiomArgJovt.jovs()[k].type())
					bytecount += axiomArgJovt.jovs()[k].type()->size();
				else
					bytecount += sizeof(ImplVal);

			if (axiomArgJovt.hasExtras())
				bytecount += sizeof(ImplVal);

			uint8_t* axiomCallStack = (uint8_t*)mStackAllocator.allocate(bytecount);

			uint8_t* curWriteArg = axiomCallStack + 
				sizeof(NativeRuntimeContinuationValue<2>) + sizeof(NativeRuntimeCallbacks*);

			long slotsWrittenTo = 0;
			long maxSlots = axiomArgJovt.jovs().size();

			ImmutableTreeVector<std::pair<ImplValContainer, Nullable<Symbol>>> tupleElts;

			auto packImplval = [&](ImplVal value, Nullable<Symbol> name) {
				if (slotsWrittenTo < maxSlots)
					{
					JOV jov = axiomArgJovt.jovs()[slotsWrittenTo];
					slotsWrittenTo++;

					//we're writing this directly into a single typed slot
					if (jov.constant())
						{
						}
						else
					if (jov.type())
						{
						memcpy(curWriteArg, value.data(), jov.type()->size());
						curWriteArg += jov.type()->size();
						}
					else
						{
						*(ImplVal*)curWriteArg = value;
						curWriteArg += sizeof(ImplVal);
						}
					}
				else
					{
					tupleElts = tupleElts + make_pair(value, name);
					}
				};

			for (long k = 0; k < args.size(); k++)
				{
				@match ControlFlowApplyArg(args[k])
					-| Normal(name, arg) ->> {
						packImplval(constructArgument(arg), name);
						}
					-| TupleCall(arg) ->> {
						ImplVal value = constructArgument(arg);

						if (!value.type().isTuple())
							packImplval(value, null());
						else
							TupleCategory::tupleIterateContentsWithNames(value, packImplval);
						}
				}

			if (tupleElts.size())
				{
				ImplValContainer tuple = ImplValContainer(tupleElts);
				ImplVal finalVal = mRefcountPool->add(tuple.getReference());
				*(ImplVal*)curWriteArg = finalVal;
				curWriteArg += sizeof(ImplVal);
				}

			lassert(curWriteArg == axiomCallStack + bytecount);

			//Inside the axiom, these should never get called.
			uword_t which = 0xFFFFFFFF;

			NativeRuntimeContinuationValue<2>& continuations(*(NativeRuntimeContinuationValue<2>*)axiomCallStack);
			NativeRuntimeCallbacks** newCallbacksPtrPtr = (NativeRuntimeCallbacks**)(axiomCallStack + sizeof(NativeRuntimeContinuationValue<2>));

			continuations.setTo(
				mTypedForaCompiler->
					generateDummyContinuation(&mCurrentFrame->getResultValue(), &which, 0, 2)
				);

			pair<NativeRuntimeContinuationValue<1>, TypedFora::Abi::VectorLoadRequest> interruptData;

			//generate new interrupts
			NativeRuntimeCallbacks newCallbacks;
			newCallbacks.resetNativeRuntimeState();
			newCallbacks.bigVectorSlotIndex = mCurrentFrame->getCallbacks()->bigVectorSlotIndex;

			newCallbacks.interruptContinuation = 
				mTypedForaCompiler->generateDummyContinuation(&interruptData, &which, 2);

			newCallbacks.cacheCallContinuation =
				mTypedForaCompiler->generateDummyContinuation(&interruptData, &which, 3);

			*newCallbacksPtrPtr = &newCallbacks;

			mTypedForaCompiler->callFunction(
				NativeRuntimeCallTarget(jumpPtr.ptr(), jumpPtr.entrypoint(), axiomCallStack),
				mStackAllocator.getMemBlockPtr()
				);

			if (which == 0)
				{
				if (normalConts.size() == 1)
					followContinuation(normalConts[0]);
				else
					{
					const auto& possibilities = axiom.resultSignature().resultPart();
					Nullable<uword_t> which = possibilities.smallestCovering(mCurrentFrame->getResultValue());
					lassert_dump(
						possibilities.size() == normalConts.size(),
						prettyPrintString(possibilities) << " vs. " << prettyPrintString(normalConts)
						);
					followContinuation(normalConts[*which]);
					}
				}
				else
			if (which == 1)
				{
				if (exceptConts.size() == 1)
					followContinuation(exceptConts[0]);
				else
					{
					const auto& possibilities = axiom.resultSignature().throwPart();
					lassert(possibilities.size() == exceptConts.size());
					Nullable<uword_t> which = possibilities.smallestCovering(mCurrentFrame->getResultValue());
					followContinuation(exceptConts[*which]);
					}
				}
				else
			if (which == 2)
				{
				mStackAllocator.free(axiomCallStack);
				followInterruptContinuation(null() << interruptData.second);
				}
			else
				lassert(false);
			}
	}

void TypedCfgInterpreter::followInterruptContinuation(const Nullable<TypedFora::Abi::VectorLoadRequest>& loadRequest)
	{
	NativeRuntimeContinuationValue<1> cont =
		mTypedForaCompiler->wrapCPPCallback(
			&TypedCfgInterpreter::interpreter,
			mCurrentFrame,
			mStackAllocator.getMemBlockPtr()
			) +
		NativeRuntimeContinuationSlot(
			continuation_execute_from_node,
			&mCurrentFrame->getResultValue()
			);

	auto continuationToFollow = mCurrentFrame->getCallbacks()->interruptContinuation;

	auto& interruptTarget = *(pair<NativeRuntimeContinuationValue<1>, TypedFora::Abi::VectorLoadRequest>*)
		continuationToFollow.slots()[0].target();

	interruptTarget.first = cont;

	if (loadRequest)
		interruptTarget.second = *loadRequest;

	mContinuationToExitAndFollow = continuationToFollow;
	}